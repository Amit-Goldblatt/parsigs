{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/royashcenazi/downloads/training_20180910\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.cli.train import train\n",
    "import spacy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a very naive start, we are training the model with the same test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: example_model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    780.61    0.00    0.00    0.00    0.00\n",
      "  2     200        231.86  244264.67    0.00    0.00    0.00    0.00\n",
      "  5     400       4432.32  38503.68    2.53   23.32    1.34    0.03\n",
      "  8     600       7686.41  25151.53    2.41    9.58    1.38    0.02\n",
      " 11     800       2554.61  16090.28   32.18   44.55   25.19    0.32\n",
      " 14    1000       2959.27  13519.22   33.94   59.74   23.70    0.34\n",
      " 17    1200       1036.97  12126.76   41.47   61.96   31.16    0.41\n",
      " 20    1400       2436.09  10057.82   57.55   66.20   50.90    0.58\n",
      " 23    1600        683.65   7884.47   61.67   68.63   55.99    0.62\n",
      " 26    1800        733.90   7153.58   65.40   70.97   60.63    0.65\n",
      " 29    2000        807.90   6394.31   67.36   73.76   61.98    0.67\n",
      " 32    2200      23520.83   6497.62   68.43   74.09   63.58    0.68\n",
      " 35    2400      13290.01   5729.79   69.62   74.86   65.07    0.70\n",
      " 38    2600       1540.09   4903.13   72.08   77.70   67.22    0.72\n",
      " 41    2800      21899.50   4881.37   73.84   78.85   69.43    0.74\n",
      " 44    3000        828.01   4078.39   74.65   79.97   70.00    0.75\n",
      " 47    3200       1654.46   3609.18   76.01   81.21   71.44    0.76\n",
      " 50    3400       6087.42   3515.82   77.02   82.72   72.05    0.77\n",
      " 52    3600       2014.76   3134.56   78.26   82.92   74.09    0.78\n",
      " 55    3800      92160.52   3315.33   78.66   84.02   73.94    0.79\n",
      " 58    4000        624.93   2622.90   79.51   84.35   75.19    0.80\n",
      " 61    4200      21197.11   2633.67   79.81   84.96   75.24    0.80\n",
      " 64    4400      12448.19   2476.19   80.24   85.46   75.62    0.80\n",
      " 67    4600       6136.96   2317.01   80.15   84.67   76.10    0.80\n",
      " 70    4800        692.78   2083.00   80.61   85.53   76.23    0.81\n",
      " 73    5000        723.52   1979.82   80.85   84.94   77.13    0.81\n",
      " 76    5200       6267.11   1987.41   80.94   85.73   76.65    0.81\n",
      " 79    5400        752.53   1740.44   81.15   85.74   77.02    0.81\n",
      " 82    5600       1538.83   1720.99   81.36   85.68   77.46    0.81\n",
      " 85    5800       1927.90   1695.15   81.49   85.95   77.46    0.81\n",
      " 88    6000       1683.42   1597.43   81.72   86.18   77.69    0.82\n",
      " 91    6200        959.85   1605.18   81.66   86.28   77.52    0.82\n",
      " 94    6400       1496.19   1459.05   81.73   86.08   77.80    0.82\n",
      " 97    6600       1743.89   1386.32   81.70   86.43   77.47    0.82\n",
      "100    6800        607.53   1292.91   81.75   86.10   77.82    0.82\n",
      "102    7000        607.44   1303.09   82.01   86.13   78.27    0.82\n",
      "105    7200        521.43   1214.93   82.07   86.80   77.83    0.82\n",
      "108    7400        472.65   1181.37   82.18   86.17   78.55    0.82\n",
      "111    7600        541.87   1164.73   82.22   86.62   78.24    0.82\n",
      "114    7800        578.25   1117.20   82.40   86.55   78.63    0.82\n",
      "117    8000        654.03   1087.61   82.43   86.76   78.51    0.82\n",
      "120    8200        424.10    900.23   82.47   86.75   78.60    0.82\n",
      "123    8400        522.41   1103.38   82.62   87.01   78.65    0.83\n",
      "126    8600        553.87   1034.58   82.54   86.98   78.54    0.83\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "example_model/model-last\n"
     ]
    }
   ],
   "source": [
    "train(\"/Users/royashcenazi/Studies/parsigs/research/config/config.cfg\",\n",
    "      output_path='example_model',\n",
    "      overrides={\"paths.train\": \"/Users/royashcenazi/downloads/first_trial.spacy\", \n",
    "                 \"paths.dev\": \"/Users/royashcenazi/downloads/first_trial.spacy\",\n",
    "                 \"training.max_epochs\": 128})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_nlp = spacy.load('./example_model/model-best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### first outcome! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'Dosage'), (tablets, 'Form'), (ibuprofen, 'Drug'), (3 times a day, 'Frequency')]\n"
     ]
    }
   ],
   "source": [
    "inp = 'take 2 tablets of ibuprofen 3 times a day'\n",
    "print([(e, e.label_) for e in trained_nlp(inp).ents])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can even parse multuple dosing instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'Dosage'), (puffs, 'Form'), (albuterol, 'Drug'), (2 times a day, 'Frequency'), (1, 'Dosage'), (puff, 'Form'), (albuterol, 'Drug'), (2 times a day, 'Frequency')]\n"
     ]
    }
   ],
   "source": [
    "inp = 'inhale 3 puffs of albuterol 2 times a day for one week' \\\n",
    "      'then 1 puff of albuterol 2 times a day'\n",
    "\n",
    "print([(e, e.label_) for e in trained_nlp(inp).ents])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are many things to improve, one example is the frequency that can and should be parsed to an interval type and amoubt (e.g type=day, amount=2)\n",
    "\n",
    "Also, the model only recognizes encountered features, so inputting to the model a new sentence, will not be parsed correctly. \n",
    "When we will use the pre-trained Bert model, this issue should be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2 times a day, 'Frequency')]\n"
     ]
    }
   ],
   "source": [
    "inp = 'apply 1 pump of fluticasone 2 times a day for 2 weeks'\n",
    "\n",
    "print([(e, e.label_) for e in trained_nlp(inp).ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
